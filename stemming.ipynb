{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee6d27b",
   "metadata": {},
   "source": [
    "##### Stemming: Stemming the process of reduce a word to it word stem that affixes to suffixes and prefix or to the roots of words known as lemma. \n",
    "##### Stemming is important in natural language understanding(NLU) and natural language process(NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ffba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"congratulation\",\"programming\",\"programs\",\"history\",\"finally\",\"finalize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f379308",
   "metadata": {},
   "source": [
    "#### Porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab174e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "writes----->write\n",
      "congratulation----->congratul\n",
      "programming----->program\n",
      "programs----->program\n",
      "history----->histori\n",
      "finally----->final\n",
      "finalize----->final\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porterstemming=PorterStemmer()\n",
    "for word in words:\n",
    "    print(word+\"----->\"+porterstemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e33803",
   "metadata": {},
   "source": [
    "##### RegexpStemmer class: NLTK has RegexpStemmer class with the help of which we can easily implement regular expression stemmer algorithm.It basically takes a single regular expression and remove any prefix or suffix that match the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220ac6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$',min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c5e91c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "continue\n"
     ]
    }
   ],
   "source": [
    "print(reg_stemmer.stem('eating'))\n",
    "print(reg_stemmer.stem(\"continueable\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c433d9",
   "metadata": {},
   "source": [
    "#### snowball stemmer : To overcome the issue we face in the porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f17fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowballstemmer=SnowballStemmer('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5bb1b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lets compare the porter stemmer and snowball stemmer\n",
    "porterstemming.stem(\"fairly\"),porterstemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f1c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem(\"fairly\"),snowballstemmer.stem(\"sportingly\") ## we get accurate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "128bb120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('goe', 'histori')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem(\"goes\"),snowballstemmer.stem(\"history\")\n",
    "## Still snowball stemmer is in acuurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5b387",
   "metadata": {},
   "source": [
    "##### but eventhough the snowball also have the issue with some words like goes,history. in this text preprocessing is not suitable for the chatbots. so we have the concept of the Lemmatization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
